{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-11-14T15:02:13.087487-08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.17\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "metapool    : 0+untagged.160.g3bf77e4.dirty\n",
      "sample_sheet: 0.13.0\n",
      "openpyxl    : 3.0.10\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 20.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: Rodolfos-MacBook-Pro-2.local\n",
      "\n",
      "json      : 2.0.9\n",
      "numpy     : 1.25.2\n",
      "pandas    : 2.0.3\n",
      "seaborn   : 0.12.2\n",
      "re        : 2.2.1\n",
      "matplotlib: 3.7.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import mannwhitneyu, zscore\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from contextlib import suppress\n",
    "from metapool.metapool import *\n",
    "from metapool.plate import PlateReplication\n",
    "from metapool import (validate_and_scrub_sample_sheet, make_sample_sheet, requires_dilution, dilute_gDNA,\n",
    "                      find_threshold, autopool, extract_stats_metadata, add_controls, compress_plates)\n",
    "%watermark -i -v -iv -m -h -p metapool,sample_sheet,openpyxl -u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knight Lab shotgun pipeline notebook\n",
    "\n",
    "### What is it?\n",
    "\n",
    "This Jupyter Notebook allows you to automatically produce most of the files you need for completing the Knight Lab shotgun sequencing pipeline.\n",
    "\n",
    "Hopefully, this will not only make it much easier to generate these files, but also keep our information more accurate.\n",
    "\n",
    "### Here's how it should work.\n",
    "\n",
    "You'll start out with a **basic plate map**, which just links each sample to it's approprite row and column.\n",
    "\n",
    "Then you'll add the output of the MiniPico assay of sample DNA concentrations, which will enable to you to automatically make a **normalization pick list** for starting the shotgun library prep itself. You can also visualize these concentrations on the plate, allowing you to double check the plate map and DNA concentration read.\n",
    "\n",
    "Next you'll automatically assign barcodes to each sample, producing an **index pick list** for barcode addition prior to PCR.\n",
    "\n",
    "After finishing the shotgun library prep itself, you'll measure library concentration with qPCR. This qPCR data file will then be read in and used to estimate and visualize pooling parameters, producing a **pooling pick list**. \n",
    "\n",
    "Finally, the per-sample information from the whole run can be combined to automatically produce a **sample sheet** that you can give directly to IGM for sequencing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for normalizing DNA\n",
    "\n",
    "This portion of the notebook will read in the output of the mini-Pico quantification assay and construct an Echo normalization picklist file. \n",
    "\n",
    "As inputs, it requires:\n",
    "1. A tab-delimited row-wise plate map that indicates the sample name, well location, and blank status of each sample on the 384 well plate.\n",
    "\n",
    "You can use this google sheet template to generate your plate map:\n",
    "https://docs.google.com/spreadsheets/d/1xPjB6iR3brGeG4bm2un4ISSsTDxFw5yME09bKqz0XNk/edit?usp=sharing\n",
    "\n",
    "The workflow then:\n",
    "1. reads in the plate map and constructs a dataframe\n",
    "2. calculates volumes to be added via echo to reach desired input DNA quantity\n",
    "3. produces an Echo-formatted pick list file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: read in Sample Accession File\n",
    "**Enter the correct path to the sample accession file**. This will serve as a source for relating all subsequent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TestCase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTests\u001b[39;00m(\u001b[43mTestCase\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetUp\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxDiff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TestCase' is not defined"
     ]
    }
   ],
   "source": [
    "class Tests(TestCase):\n",
    "    def setUp(self):\n",
    "        self.maxDiff = None\n",
    "        self.cp_vals = np.array([[10.14, 7.89, 7.9, 15.48],\n",
    "                                 [7.86, 8.07, 8.16, 9.64],\n",
    "                                 [12.29, 7.64, 7.32, 13.74]])\n",
    "\n",
    "        self.dna_vals = np.array([[10.14, 7.89, 7.9, 15.48],\n",
    "                                  [7.86, 8.07, 8.16, 9.64],\n",
    "                                  [12.29, 7.64, 7.32, 13.74]])\n",
    "\n",
    "        self.qpcr_conc = \\\n",
    "            np.array([[98.14626462, 487.8121413, 484.3480866, 2.183406934],\n",
    "                      [498.3536649, 429.0839787, 402.4270321, 140.1601735],\n",
    "                      [21.20533391, 582.9456031, 732.2655041, 7.545145988]])\n",
    "\n",
    "        self.pico_conc = \\\n",
    "            np.array([[38.4090909, 29.8863636, 29.9242424, 58.6363636],\n",
    "                      [29.7727273, 30.5681818, 30.9090909, 36.5151515],\n",
    "                      [46.5530303, 28.9393939, 27.7272727, 52.0454545]])\n",
    "\n",
    "        path = os.path.dirname(__file__)\n",
    "        plate_fp = os.path.join(path, 'data/test_plate_map.tsv')\n",
    "        counts_fp = os.path.join(path, 'data/test_filtered_counts.tsv')\n",
    "        counts_ps_fp = os.path.join(path, 'data/test_per_sample_fastq.tsv')\n",
    "        no_blanks_fp = os.path.join(path, 'data/test_no_blanks.tsv')\n",
    "        blanks_fp = os.path.join(path, 'data/test_blanks.tsv')\n",
    "        with_nan_fp = os.path.join(path, 'data/test_nan.tsv')\n",
    "\n",
    "        sa_fp = os.path.join(path, 'data/sa_file.tsv')\n",
    "        p1 = os.path.join(path, 'data/plate_map1.tsv')\n",
    "        p2 = os.path.join(path, 'data/plate_map2.tsv')\n",
    "        p3 = os.path.join(path, 'data/plate_map3.tsv')\n",
    "        p4 = os.path.join(path, 'data/plate_map4.tsv')\n",
    "\n",
    "        self.comp_plate_exp_fp = os.path.join(\n",
    "            path,\n",
    "            'data/compress_plates_expected_out.tsv')\n",
    "        self.add_controls_exp_fp = os.path.join(\n",
    "            path,\n",
    "            'data/add_controls_expected_out.tsv')\n",
    "        self.katharoseq_dir = os.path.join(path, 'data/katharo')\n",
    "        self.blanks_dir = os.path.join(path, 'data/blanks')\n",
    "\n",
    "        self.plate_df = pd.read_csv(plate_fp, sep=',')\n",
    "        self.counts_df = pd.read_csv(counts_fp, sep=',')\n",
    "        self.counts_df_ps = pd.read_csv(counts_ps_fp, sep=',')\n",
    "        self.no_blanks = pd.read_csv(no_blanks_fp, sep='\\t')\n",
    "        self.with_nan = pd.read_csv(with_nan_fp, sep='\\t')\n",
    "        self.blanks = pd.read_csv(blanks_fp, sep='\\t')\n",
    "        self.sa_df = pd.read_csv(sa_fp, sep='\\t',\n",
    "                                 dtype={'TubeCode': str})\n",
    "        self.fp = path\n",
    "        self.plates = [p1, p2, p3, p4]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def test_validate_plate_df(self):\n",
    "        plate_df = pd.read_csv(self.comp_plate_exp_fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compress_plates():\n",
    "    compression = [\n",
    "        # top left plate\n",
    "        {'Plate Position': 1,  # as int\n",
    "         'Plate map file': '../metapool/tests/data/plate_map1.tsv',\n",
    "         'Project Plate': 'Celeste_Adaptation_12986_Plate_16',\n",
    "         'Project Name': 'Celeste_Adaptation_12986',\n",
    "         'Project Abbreviation': 'ADAPT'},\n",
    "        # top right plate\n",
    "        {'Plate Position': 2,\n",
    "         'Plate map file': '../metapool/tests/data/plate_map2.tsv',\n",
    "         'Project Plate': 'Celeste_Adaptation_12986_Plate_17',\n",
    "         'Project Name': 'Celeste_Adaptation_12986',\n",
    "         'Project Abbreviation': 'ADAPT'},\n",
    "        {'Plate Position': 3,\n",
    "         'Plate map file': '../metapool/tests/data/plate_map3.tsv',\n",
    "         'Project Plate': 'Celeste_Adaptation_12986_Plate_18',\n",
    "         'Project Name': 'Celeste_Adaptation_12986',\n",
    "         'Project Abbreviation': 'ADAPT'},\n",
    "        {'Plate Position': 4,\n",
    "         'Plate map file': '../metapool/tests/data/plate_map4.tsv',\n",
    "         'Project Plate': 'Celeste_Adaptation_12986_21',\n",
    "         'Project Name': 'Celeste_Adaptation_12986',\n",
    "         'Project Abbreviation': 'ADAPT'}\n",
    "    ]\n",
    "\n",
    "    sa_df = pd.read_csv('../metapool/tests/data/sa_file.tsv', sep='\\t',\n",
    "                             dtype={'TubeCode': str})\n",
    "\n",
    "    plate_df_obs = compress_plates(\n",
    "        compression,\n",
    "        sa_df,\n",
    "        well_col='Well')\n",
    "    plate_df_exp = pd.read_csv('../metapool/tests/data/compress_plates_expected_out.tsv',\n",
    "                               dtype={'TubeCode': str}, sep='\\t')\n",
    "\n",
    "    pd.testing.assert_frame_equal(plate_df_obs, plate_df_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compress_plates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_controls():\n",
    "    plate_df = pd.read_csv('../metapool/tests/data/compress_plates_expected_out.tsv',\n",
    "                               dtype={'TubeCode': str}, sep='\\t')\n",
    "\n",
    "    add_controls_obs = add_controls(\n",
    "        plate_df,\n",
    "        '../metapool/tests/data/blanks/',\n",
    "        '../metapool/tests/data/katharo/')\n",
    "    add_controls_exp = pd.read_csv('../metapool/tests/data/add_controls_expected_out.tsv',\n",
    "                                   dtype={'TubeCode': str,\n",
    "                                          'Kathseq_RackID': str}, sep='\\t')\n",
    "\n",
    "    pd.testing.assert_frame_equal(add_controls_obs,\n",
    "                                  add_controls_exp)\n",
    "\n",
    "    # Testing edge case that technician reruns the \n",
    "    # module on the same dataframe\n",
    "    add_controls_obs = add_controls(add_controls_exp,\n",
    "                                    '../metapool/tests/data/blanks/',\n",
    "                                    '../metapool/tests/data/katharo/')\n",
    "\n",
    "    pd.testing.assert_frame_equal(add_controls_obs,\n",
    "                                  add_controls_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls added\n",
      "Plate dataframe input already had controls. Returning unmodified input\n"
     ]
    }
   ],
   "source": [
    "test_add_controls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_controls_exp = pd.read_csv('../metapool/tests/data/add_controls_expected_out.tsv',\n",
    "                                   dtype={'TubeCode': str,\n",
    "                                          'Kathseq_RackID': str}, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 control samples in this plate\n",
      "There are 357 samples with associated metadata in this plate\n",
      "All samples have associated metadata :D\n",
      "All TubeCodes have associated data :D\n"
     ]
    }
   ],
   "source": [
    "blanks_dir = './test_data/BLANKS/'\n",
    "katharoseq_dir = './test_data/katharoseq/'\n",
    "\n",
    "metadata_fp = './test_data/Plate_Maps/12986_20230314-090655.txt'\n",
    "if not os.path.isfile(sample_accession_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)\n",
    "\n",
    "metadata = pd.read_csv(metadata_fp,\n",
    "                                 sep='\\t')\n",
    "\n",
    "sample_accession_fp = './test_data/Plate_Maps/2022_summer_Celeste_Adaptation_16_17_18_21_sa_file.tsv'\n",
    "if not os.path.isfile(sample_accession_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)\n",
    "\n",
    "sample_accession_df = pd.read_csv(sample_accession_fp,dtype={'TubeCode':str,\n",
    "                                                            'sample_name':str},\n",
    "                                 sep='\\t')\n",
    "\n",
    "validate_plate_df(add_controls_exp,metadata,sample_accession_df,blanks_dir,katharoseq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 control samples in this plate\n",
      "There are 357 samples with associated metadata in this plate\n",
      "All samples have associated metadata :D\n",
      "All TubeCodes have associated data :D\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "There should be 8 dilution points of katharoseq controls and your plate_df only has 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvalidate_plate_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_controls_exp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m240000.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1200000.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_accession_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mblanks_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkatharoseq_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Work/Git/metagenomics_pooling_notebook/metapool/metapool.py:1798\u001b[0m, in \u001b[0;36mvalidate_plate_df\u001b[0;34m(plate_df, metadata, sample_accession_df, blanks_dir, katharoseq_dir)\u001b[0m\n\u001b[1;32m   1794\u001b[0m     dilutions_ \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   1795\u001b[0m         plate_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mplate_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_cells\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull(),\n\u001b[1;32m   1796\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_cells\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dilutions_ \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[0;32m-> 1798\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere should be 8 dilution points of katharoseq\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1799\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m controls and your plate_df only has\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1800\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilutions_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;66;03m# remove any leading and/or trailing whitespace before determining if\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;66;03m# any of the sample-names are invalid or duplicates.\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;66;03m# copied from read_plate_map_csv()\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m plate_df \u001b[38;5;241m=\u001b[39m sanitize_plate_map_sample_names(plate_df)\n",
      "\u001b[0;31mValueError\u001b[0m: There should be 8 dilution points of katharoseq controls and your plate_df only has 7"
     ]
    }
   ],
   "source": [
    "validate_plate_df(add_controls_exp.replace(240000.0,1200000.0),\n",
    "                  metadata,sample_accession_df,blanks_dir,katharoseq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Col</th>\n",
       "      <th>Compressed Plate Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Plate Position</th>\n",
       "      <th>Project Abbreviation</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Project Plate</th>\n",
       "      <th>RackID</th>\n",
       "      <th>Row</th>\n",
       "      <th>Time</th>\n",
       "      <th>TubeCode</th>\n",
       "      <th>Well</th>\n",
       "      <th>well_id_96</th>\n",
       "      <th>description</th>\n",
       "      <th>Kathseq_RackID</th>\n",
       "      <th>number_of_cells</th>\n",
       "      <th>Blank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_in_metadata</td>\n",
       "      <td>1</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>1</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_Plate_16</td>\n",
       "      <td>plate_1</td>\n",
       "      <td>A</td>\n",
       "      <td>09:26:10</td>\n",
       "      <td>0363132553</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41B.Month6.10</td>\n",
       "      <td>2</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>1</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_Plate_16</td>\n",
       "      <td>plate_1</td>\n",
       "      <td>A</td>\n",
       "      <td>09:26:10</td>\n",
       "      <td>0363132554</td>\n",
       "      <td>A3</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41B.Month6.11</td>\n",
       "      <td>3</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>1</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_Plate_16</td>\n",
       "      <td>plate_1</td>\n",
       "      <td>A</td>\n",
       "      <td>09:26:10</td>\n",
       "      <td>0363132555</td>\n",
       "      <td>A5</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41B.Month6.12</td>\n",
       "      <td>4</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>1</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_Plate_16</td>\n",
       "      <td>plate_1</td>\n",
       "      <td>A</td>\n",
       "      <td>09:26:10</td>\n",
       "      <td>0363132556</td>\n",
       "      <td>A7</td>\n",
       "      <td>A4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41B.Month6.13</td>\n",
       "      <td>5</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>1</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_Plate_16</td>\n",
       "      <td>plate_1</td>\n",
       "      <td>A</td>\n",
       "      <td>09:26:10</td>\n",
       "      <td>0363132557</td>\n",
       "      <td>A9</td>\n",
       "      <td>A5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>kathseq.1200000.0.H8</td>\n",
       "      <td>8</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>4</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_21</td>\n",
       "      <td>plate_4</td>\n",
       "      <td>H</td>\n",
       "      <td>09:30:11</td>\n",
       "      <td>0363159642</td>\n",
       "      <td>P16</td>\n",
       "      <td>H8</td>\n",
       "      <td>positive_control</td>\n",
       "      <td>12345678</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>kathseq.1200000.0.H9</td>\n",
       "      <td>9</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>4</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_21</td>\n",
       "      <td>plate_4</td>\n",
       "      <td>H</td>\n",
       "      <td>09:30:11</td>\n",
       "      <td>0363159665</td>\n",
       "      <td>P18</td>\n",
       "      <td>H9</td>\n",
       "      <td>positive_control</td>\n",
       "      <td>12345678</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>kathseq.1200000.0.H10</td>\n",
       "      <td>10</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>4</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_21</td>\n",
       "      <td>plate_4</td>\n",
       "      <td>H</td>\n",
       "      <td>09:30:11</td>\n",
       "      <td>0363159649</td>\n",
       "      <td>P20</td>\n",
       "      <td>H10</td>\n",
       "      <td>positive_control</td>\n",
       "      <td>12345678</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>kathseq.1200000.0.H11</td>\n",
       "      <td>11</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>4</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_21</td>\n",
       "      <td>plate_4</td>\n",
       "      <td>H</td>\n",
       "      <td>09:30:11</td>\n",
       "      <td>0363159633</td>\n",
       "      <td>P22</td>\n",
       "      <td>H11</td>\n",
       "      <td>positive_control</td>\n",
       "      <td>12345678</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>kathseq.240000.0.H12</td>\n",
       "      <td>12</td>\n",
       "      <td>Celeste_Adaptation_12986_16_17_18_21</td>\n",
       "      <td>20230627</td>\n",
       "      <td>4</td>\n",
       "      <td>ADAPT</td>\n",
       "      <td>Celeste_Adaptation_12986</td>\n",
       "      <td>Celeste_Adaptation_12986_21</td>\n",
       "      <td>plate_4</td>\n",
       "      <td>H</td>\n",
       "      <td>09:30:11</td>\n",
       "      <td>0363159669</td>\n",
       "      <td>P24</td>\n",
       "      <td>H12</td>\n",
       "      <td>positive_control</td>\n",
       "      <td>12345678</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sample  Col                 Compressed Plate Name  \\\n",
       "0          not_in_metadata    1  Celeste_Adaptation_12986_16_17_18_21   \n",
       "1            41B.Month6.10    2  Celeste_Adaptation_12986_16_17_18_21   \n",
       "2            41B.Month6.11    3  Celeste_Adaptation_12986_16_17_18_21   \n",
       "3            41B.Month6.12    4  Celeste_Adaptation_12986_16_17_18_21   \n",
       "4            41B.Month6.13    5  Celeste_Adaptation_12986_16_17_18_21   \n",
       "..                     ...  ...                                   ...   \n",
       "379   kathseq.1200000.0.H8    8  Celeste_Adaptation_12986_16_17_18_21   \n",
       "380   kathseq.1200000.0.H9    9  Celeste_Adaptation_12986_16_17_18_21   \n",
       "381  kathseq.1200000.0.H10   10  Celeste_Adaptation_12986_16_17_18_21   \n",
       "382  kathseq.1200000.0.H11   11  Celeste_Adaptation_12986_16_17_18_21   \n",
       "383   kathseq.240000.0.H12   12  Celeste_Adaptation_12986_16_17_18_21   \n",
       "\n",
       "         Date  Plate Position Project Abbreviation              Project Name  \\\n",
       "0    20230627               1                ADAPT  Celeste_Adaptation_12986   \n",
       "1    20230627               1                ADAPT  Celeste_Adaptation_12986   \n",
       "2    20230627               1                ADAPT  Celeste_Adaptation_12986   \n",
       "3    20230627               1                ADAPT  Celeste_Adaptation_12986   \n",
       "4    20230627               1                ADAPT  Celeste_Adaptation_12986   \n",
       "..        ...             ...                  ...                       ...   \n",
       "379  20230627               4                ADAPT  Celeste_Adaptation_12986   \n",
       "380  20230627               4                ADAPT  Celeste_Adaptation_12986   \n",
       "381  20230627               4                ADAPT  Celeste_Adaptation_12986   \n",
       "382  20230627               4                ADAPT  Celeste_Adaptation_12986   \n",
       "383  20230627               4                ADAPT  Celeste_Adaptation_12986   \n",
       "\n",
       "                         Project Plate   RackID Row      Time    TubeCode  \\\n",
       "0    Celeste_Adaptation_12986_Plate_16  plate_1   A  09:26:10  0363132553   \n",
       "1    Celeste_Adaptation_12986_Plate_16  plate_1   A  09:26:10  0363132554   \n",
       "2    Celeste_Adaptation_12986_Plate_16  plate_1   A  09:26:10  0363132555   \n",
       "3    Celeste_Adaptation_12986_Plate_16  plate_1   A  09:26:10  0363132556   \n",
       "4    Celeste_Adaptation_12986_Plate_16  plate_1   A  09:26:10  0363132557   \n",
       "..                                 ...      ...  ..       ...         ...   \n",
       "379        Celeste_Adaptation_12986_21  plate_4   H  09:30:11  0363159642   \n",
       "380        Celeste_Adaptation_12986_21  plate_4   H  09:30:11  0363159665   \n",
       "381        Celeste_Adaptation_12986_21  plate_4   H  09:30:11  0363159649   \n",
       "382        Celeste_Adaptation_12986_21  plate_4   H  09:30:11  0363159633   \n",
       "383        Celeste_Adaptation_12986_21  plate_4   H  09:30:11  0363159669   \n",
       "\n",
       "    Well well_id_96       description Kathseq_RackID  number_of_cells  Blank  \n",
       "0     A1         A1               NaN            NaN              NaN  False  \n",
       "1     A3         A2               NaN            NaN              NaN  False  \n",
       "2     A5         A3               NaN            NaN              NaN  False  \n",
       "3     A7         A4               NaN            NaN              NaN  False  \n",
       "4     A9         A5               NaN            NaN              NaN  False  \n",
       "..   ...        ...               ...            ...              ...    ...  \n",
       "379  P16         H8  positive_control       12345678        1200000.0  False  \n",
       "380  P18         H9  positive_control       12345678        1200000.0  False  \n",
       "381  P20        H10  positive_control       12345678        1200000.0  False  \n",
       "382  P22        H11  positive_control       12345678        1200000.0  False  \n",
       "383  P24        H12  positive_control       12345678         240000.0  False  \n",
       "\n",
       "[384 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>TubeCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23B.Day7.1</td>\n",
       "      <td>0359097394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23B.Day7.10</td>\n",
       "      <td>0359097402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23B.Day7.11</td>\n",
       "      <td>0359097385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23B.Day7.12</td>\n",
       "      <td>0359097375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23B.Day7.13</td>\n",
       "      <td>0359098882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_name    TubeCode\n",
       "0   23B.Day7.1  0359097394\n",
       "1  23B.Day7.10  0359097402\n",
       "2  23B.Day7.11  0359097385\n",
       "3  23B.Day7.12  0359097375\n",
       "4  23B.Day7.13  0359098882"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_accession_fp = './test_data/Plate_Maps/2022_summer_Celeste_Adaptation_16_17_18_21_sa_file.tsv'\n",
    "if not os.path.isfile(sample_accession_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)\n",
    "\n",
    "sample_accession_df = pd.read_csv(sample_accession_fp,dtype={'TubeCode':str,\n",
    "                                                            'sample_name':str},\n",
    "                                 sep='\\t')\n",
    "sample_accession_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read in the sample info from Qiita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>bacteria_strain</th>\n",
       "      <th>box_id</th>\n",
       "      <th>cage_id</th>\n",
       "      <th>collection_timepoint</th>\n",
       "      <th>collection_timestamp</th>\n",
       "      <th>dam</th>\n",
       "      <th>date_collected</th>\n",
       "      <th>date_colonized</th>\n",
       "      <th>decription</th>\n",
       "      <th>...</th>\n",
       "      <th>qiita_study_id</th>\n",
       "      <th>run</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>sex</th>\n",
       "      <th>sire</th>\n",
       "      <th>taxon_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tube_id</th>\n",
       "      <th>zarrinparlab_quant_ng_ul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12986.23B.Day7.1</td>\n",
       "      <td>AZ20</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>day7</td>\n",
       "      <td>2017-07-19 10:00</td>\n",
       "      <td>A1</td>\n",
       "      <td>7/19/17</td>\n",
       "      <td>7/12/17 0:00</td>\n",
       "      <td>23B.Day7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>12986</td>\n",
       "      <td>1</td>\n",
       "      <td>fecal culture</td>\n",
       "      <td>mouse gut metagenome</td>\n",
       "      <td>male</td>\n",
       "      <td>A</td>\n",
       "      <td>410661</td>\n",
       "      <td>In Vivo Adaptation of Engineered Native Bacteria</td>\n",
       "      <td>23b-1_day7</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12986.23B.Day7.10</td>\n",
       "      <td>AZ20</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>day7</td>\n",
       "      <td>2017-07-19 10:00</td>\n",
       "      <td>A1</td>\n",
       "      <td>7/19/17</td>\n",
       "      <td>7/12/17 0:00</td>\n",
       "      <td>23B.Day7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>12986</td>\n",
       "      <td>1</td>\n",
       "      <td>fecal culture</td>\n",
       "      <td>mouse gut metagenome</td>\n",
       "      <td>male</td>\n",
       "      <td>A</td>\n",
       "      <td>410661</td>\n",
       "      <td>In Vivo Adaptation of Engineered Native Bacteria</td>\n",
       "      <td>23b-10_day7</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12986.23B.Day7.11</td>\n",
       "      <td>AZ20</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>day7</td>\n",
       "      <td>2017-07-19 10:00</td>\n",
       "      <td>A1</td>\n",
       "      <td>7/19/17</td>\n",
       "      <td>7/12/17 0:00</td>\n",
       "      <td>23B.Day7.11</td>\n",
       "      <td>...</td>\n",
       "      <td>12986</td>\n",
       "      <td>1</td>\n",
       "      <td>fecal culture</td>\n",
       "      <td>mouse gut metagenome</td>\n",
       "      <td>male</td>\n",
       "      <td>A</td>\n",
       "      <td>410661</td>\n",
       "      <td>In Vivo Adaptation of Engineered Native Bacteria</td>\n",
       "      <td>23b-11_day7</td>\n",
       "      <td>80.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12986.23B.Day7.12</td>\n",
       "      <td>AZ20</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>day7</td>\n",
       "      <td>2017-07-19 10:00</td>\n",
       "      <td>A1</td>\n",
       "      <td>7/19/17</td>\n",
       "      <td>7/12/17 0:00</td>\n",
       "      <td>23B.Day7.12</td>\n",
       "      <td>...</td>\n",
       "      <td>12986</td>\n",
       "      <td>1</td>\n",
       "      <td>fecal culture</td>\n",
       "      <td>mouse gut metagenome</td>\n",
       "      <td>male</td>\n",
       "      <td>A</td>\n",
       "      <td>410661</td>\n",
       "      <td>In Vivo Adaptation of Engineered Native Bacteria</td>\n",
       "      <td>23b-12_day7</td>\n",
       "      <td>49.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12986.23B.Day7.13</td>\n",
       "      <td>AZ20</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>day7</td>\n",
       "      <td>2017-07-19 10:00</td>\n",
       "      <td>A1</td>\n",
       "      <td>7/19/17</td>\n",
       "      <td>7/12/17 0:00</td>\n",
       "      <td>23B.Day7.13</td>\n",
       "      <td>...</td>\n",
       "      <td>12986</td>\n",
       "      <td>1</td>\n",
       "      <td>fecal culture</td>\n",
       "      <td>mouse gut metagenome</td>\n",
       "      <td>male</td>\n",
       "      <td>A</td>\n",
       "      <td>410661</td>\n",
       "      <td>In Vivo Adaptation of Engineered Native Bacteria</td>\n",
       "      <td>23b-13_day7</td>\n",
       "      <td>48.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_name bacteria_strain box_id cage_id collection_timepoint  \\\n",
       "0   12986.23B.Day7.1            AZ20     10      23                 day7   \n",
       "1  12986.23B.Day7.10            AZ20     10      23                 day7   \n",
       "2  12986.23B.Day7.11            AZ20     10      23                 day7   \n",
       "3  12986.23B.Day7.12            AZ20     10      23                 day7   \n",
       "4  12986.23B.Day7.13            AZ20     14      23                 day7   \n",
       "\n",
       "  collection_timestamp dam date_collected date_colonized   decription  ...  \\\n",
       "0     2017-07-19 10:00  A1        7/19/17   7/12/17 0:00   23B.Day7.1  ...   \n",
       "1     2017-07-19 10:00  A1        7/19/17   7/12/17 0:00  23B.Day7.10  ...   \n",
       "2     2017-07-19 10:00  A1        7/19/17   7/12/17 0:00  23B.Day7.11  ...   \n",
       "3     2017-07-19 10:00  A1        7/19/17   7/12/17 0:00  23B.Day7.12  ...   \n",
       "4     2017-07-19 10:00  A1        7/19/17   7/12/17 0:00  23B.Day7.13  ...   \n",
       "\n",
       "  qiita_study_id run    sample_type       scientific_name   sex sire taxon_id  \\\n",
       "0          12986   1  fecal culture  mouse gut metagenome  male    A   410661   \n",
       "1          12986   1  fecal culture  mouse gut metagenome  male    A   410661   \n",
       "2          12986   1  fecal culture  mouse gut metagenome  male    A   410661   \n",
       "3          12986   1  fecal culture  mouse gut metagenome  male    A   410661   \n",
       "4          12986   1  fecal culture  mouse gut metagenome  male    A   410661   \n",
       "\n",
       "                                              title      tube_id  \\\n",
       "0  In Vivo Adaptation of Engineered Native Bacteria   23b-1_day7   \n",
       "1  In Vivo Adaptation of Engineered Native Bacteria  23b-10_day7   \n",
       "2  In Vivo Adaptation of Engineered Native Bacteria  23b-11_day7   \n",
       "3  In Vivo Adaptation of Engineered Native Bacteria  23b-12_day7   \n",
       "4  In Vivo Adaptation of Engineered Native Bacteria  23b-13_day7   \n",
       "\n",
       "  zarrinparlab_quant_ng_ul  \n",
       "0                       78  \n",
       "1                     53.3  \n",
       "2                     80.6  \n",
       "3                     49.1  \n",
       "4                     48.6  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_fp = './test_data/Plate_Maps/12986_20230314-090655.txt'\n",
    "if not os.path.isfile(sample_accession_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)\n",
    "\n",
    "metadata = pd.read_csv(metadata_fp,\n",
    "                                 sep='\\t')\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assign the Compression Layout and Fill in Appropriate Info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_layout = [\n",
    "    {\n",
    "        # top left plate\n",
    "        'Plate Position': 1, #as int\n",
    "        'Plate map file': './test_data/Plate_Maps/2022_summer_Celeste_Adaptation_16_plate_map.tsv',\n",
    "        'Project Plate': 'Celeste_Adaptation_12986_Plate_16', # PROJECTNAME_QIITA_ID_Plate_#\n",
    "        'Project Name': 'Celeste_Adaptation_12986', # PROJECTNAME_QIITAID\n",
    "        'Project Abbreviation' : 'ADAPT', # PROJECT ABBREVIATION\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "    {\n",
    "        # top right plate\n",
    "        'Plate Position': 2,\n",
    "        'Plate map file': './test_data/Plate_Maps/2022_summer_Celeste_Adaptation_17_plate_map.tsv',\n",
    "        'Project Plate': 'Celeste_Adaptation_12986_Plate_17', # PROJECTNAME_QIITA_ID_Plate_#\n",
    "        'Project Name': 'Celeste_Adaptation_12986', # PROJECTNAME_QIITAID\n",
    "        'Project Abbreviation' : 'ADAPT', # PROJECT ABBREVIATION\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "    {\n",
    "        # bottom left plate\n",
    "        'Plate Position': 3,\n",
    "        'Plate map file': './test_data/Plate_Maps/2022_summer_Celeste_Adaptation_18_plate_map.tsv',\n",
    "        'Project Plate': 'Celeste_Adaptation_12986_Plate_18', # PROJECTNAME_QIITA_ID_Plate_#\n",
    "        'Project Name': 'Celeste_Adaptation_12986', # PROJECTNAME_QIITAID\n",
    "        'Project Abbreviation' : 'ADAPT', # PROJECT ABBREVIATION\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "    {\n",
    "        # bottom right plate\n",
    "        'Plate Position': 4,\n",
    "        'Plate map file': './test_data/Plate_Maps/2022_summer_Celeste_Adaptation_21_plate_map.tsv',\n",
    "        'Project Plate': 'Celeste_Adaptation_12986_21', # PROJECTNAME_QIITA_ID_Plate_#\n",
    "        'Project Name': 'Celeste_Adaptation_12986', # PROJECTNAME_QIITAID\n",
    "        'Project Abbreviation' : 'ADAPT', # PROJECT ABBREVIATION\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_col='Well'\n",
    "plate_df = compress_plates(compression_layout,sample_accession_df,well_col=well_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blanks_dir = './test_data/BLANKS/'\n",
    "katharoseq_dir = './test_data/katharoseq/'\n",
    "\n",
    "plate_df = add_controls(plate_df,blanks_dir,katharoseq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df.to_csv('../metapool/tests/data/add_controls_expected_out.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate plate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_plate_df(plate_df,metadata,sample_accession_df,blanks_dir,katharoseq_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: read in DNA concentrations and add to plate map\n",
    "\n",
    "**Enter the correct path to the Pico DNA concentration output**. This should be a csv-formatted file produced by the MiniPico assay on the condensed, 384-well plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_concs_fp = './test_data/Quant/MiniPico/2022_07_Celeste_Adaptation_16_17_18_21_gDNA_quant.txt'\n",
    "\n",
    "if not os.path.isfile(sample_concs_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the DNA concentration output file**. It should look something like this:\n",
    "    \n",
    "```\n",
    "Results\n",
    "\n",
    "Well ID\tWell\t[Blanked-RFU]\t[Concentration]\n",
    "SPL1\tA1\t5243.000\t3.432\n",
    "SPL2\tC1\t4949.000\t3.239\n",
    "SPL3\tE1\t15302.000\t10.016\n",
    "SPL4\tG1\t4039.000\t2.644\n",
    "SPL5\tI1\t12862.000\t8.419\n",
    "SPL6\tK1\t2840.000\t1.859\n",
    "SPL7\tM1\t3343.000\t2.188\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_concs = read_pico_csv(sample_concs_fp, plate_reader='SpectraMax_i3x')\n",
    "\n",
    "plate_df = pd.merge(plate_df, sample_concs, on=well_col)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if requires_dilution(plate_df,threshold=10,tolerance=.10):\n",
    "    plate_df = dilute_gDNA(plate_df,threshold=10)\n",
    "    print('You need to make a 1:10 gDNA dilution plate.')\n",
    "else:\n",
    "    plate_df['Diluted'] = False\n",
    "    print('Proceed w/out gDNA dilutions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize plate DNA concentrations and plate map:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get DNA concentratin information\n",
    "dna_concs = make_2D_array(plate_df, data_col='Sample DNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "# get information for annotation\n",
    "names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "\n",
    "plot_plate_vals(dna_concs,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sample replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of replicates\n",
    "\n",
    "# replicate_dict = {source1_quadrant:destination1_quadrant}\n",
    "# replicate_dict = {source1_quadrant:[destination1_quadrants,destination1_quadrants]}\n",
    "\n",
    "#replicate_dict = {1:[2,3]}\n",
    "\n",
    "# initialize a new PlateReplication object to manage metadata, conversions, and more for you.\n",
    "# initialize w/preferred well_col.\n",
    "well_col = 'Library Well'\n",
    "pr = PlateReplication(well_col)\n",
    "\n",
    "# set overwrite=False to detect any overwriting of source or destination quads and raise an Error.\n",
    "# replace replicates = None with replicates = replicate_dict to make replicates\n",
    "plate_df = pr.make_replicates(plate_df, replicates=None, overwrite=True)\n",
    "\n",
    "#replicates overlapping sample_wells for other samples shuld raise warning, but will be allowed\n",
    "if 'True' in plate_df['contains_replicates'].unique():\n",
    "    plate_df['contains_replicates'] = True\n",
    "    # get DNA concentratin information\n",
    "    dna_concs = make_2D_array(plate_df, data_col='Sample DNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "    # get information for annotation\n",
    "    names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "\n",
    "    plot_plate_vals(dna_concs,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.6s')\n",
    "else:\n",
    "    plate_df['contains_replicates'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mask arrays for even and odd rows and columns\n",
    "\n",
    "even_rows = [x for x in range(16) if x % 2 == 0]\n",
    "odd_rows = [x for x in range(16) if x % 2 == 1]\n",
    "even_cols = [x for x in range(24) if x % 2 == 0]\n",
    "odd_cols = [x for x in range(24) if x % 2 == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gDNA concentration heatmap, Plate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_plate_vals(dna_concs[np.ix_(even_rows,even_cols)],\n",
    "                annot_str= names[np.ix_(even_rows,even_cols)],\n",
    "                color_map='viridis',\n",
    "                annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gDNA concentration heatmap, Plate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_plate_vals(dna_concs[np.ix_(even_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(even_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gDNA concentration heatmap, Plate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(dna_concs[np.ix_(odd_rows,even_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,even_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gDNA concentration heatmap, Plate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_plate_vals(dna_concs[np.ix_(odd_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: calculate normalization volumes and add to plate map\n",
    "\n",
    "This step will calculate volumes for the DNA normalization pick list.\n",
    "\n",
    "Check the desired values for:\n",
    " - **`ng`**: the desired quantity of DNA in normed plate, in ng\n",
    " - **`total_vol`**: the total volume of normalized DNA, in nL\n",
    " - **`min_vol`**: the minimum quantity of sample to add, in nL\n",
    " - **`resolution`**: the resolution of the Echo, in nL (usually 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = 5\n",
    "total_vol = 3500\n",
    "min_vol = 25\n",
    "resolution = 2.5\n",
    "\n",
    "dna_vols = calculate_norm_vol(plate_df['Sample DNA Concentration'], ng=ng, min_vol=min_vol, max_vol=total_vol, resolution=resolution)\n",
    "water_vols = total_vol - dna_vols\n",
    "\n",
    "plate_df['Normalized DNA volume'] = dna_vols\n",
    "plate_df['Normalized water volume'] = water_vols\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a (optional): Add synDNA spike-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df = add_syndna(plate_df,syndna_pool_number=None,syndna_concentration=2.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plate_df['synDNA pool number'].unique()!= None:\n",
    "    syndna_well='A1'\n",
    "    syndna_plate = 'synDNA plate'\n",
    "    syndna_picklist = format_dna_norm_picklist(np.array(plate_df['synDNA volume']),\n",
    "                                             np.zeros(plate_df.shape[0]),\n",
    "                                             np.repeat(syndna_well,plate_df.shape[0]),\n",
    "                                             dest_wells = np.array(plate_df[well_col]),\n",
    "                                             sample_names = np.array(plate_df['Sample']),\n",
    "                                             sample_plates = np.repeat(syndna_plate,plate_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plate_df['synDNA pool number'].unique() != None:\n",
    "    # Write the picklist as .txt\n",
    "    syndna_picklist_fp = './test_output/Input_Norm/YYYY_MM_DD_Celeste_Adaptation_16-21_syndna.txt'\n",
    "\n",
    "    if os.path.isfile(syndna_picklist_fp):\n",
    "        print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plate_df['synDNA pool number'].unique() != None:\n",
    "    with open(syndna_picklist_fp, 'w') as f:\n",
    "        f.write(syndna_picklist)\n",
    "\n",
    "    !head {syndna_picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: make pick list\n",
    "\n",
    "Format the Echo-compatible pick list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_picklist = format_dna_norm_picklist(np.array(plate_df['Normalized DNA volume']),\n",
    "                                         np.array(plate_df['Normalized water volume']),\n",
    "                                         np.array(plate_df['Well']),\n",
    "                                         dest_wells = np.array(plate_df[well_col]),\n",
    "                                         sample_names = np.array(plate_df['Sample']),\n",
    "                                         sample_plates = np.array(plate_df['Compressed Plate Name']),\n",
    "                                         dna_concs = np.array(plate_df['Sample DNA Concentration']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: write pick list to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .txt\n",
    "norm_picklist_fp = './test_output/Input_Norm/YYYY_MM_DD_Celeste_Adaptation_16-21_inputnorm.txt'\n",
    "\n",
    "if os.path.isfile(norm_picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(norm_picklist_fp, 'w') as f:\n",
    "    f.write(norm_picklist)\n",
    "    \n",
    "!head {norm_picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for assigning barcodes\n",
    "\n",
    "This portion of the notebook will assign index values and construct an Echo picklist file for adding barcodes. \n",
    "\n",
    "As inputs, it requires:\n",
    "1. A plate map dataframe (from previous step)\n",
    "2. A tab-delimited index combination file, relating index combinations, i5 and i7 index values, and i5 and i7 index locations\n",
    "\n",
    "The workflow then:\n",
    "1. reads in the index combo list\n",
    "2. assigns indices per sample\n",
    "3. produces an Echo-formatted pick list file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in index combo list\n",
    "\n",
    "This is a file that contains every possible i5 and i7 barcode combo on a separate line,\n",
    "along with plate and well location information. It should look something like this:\n",
    "\n",
    "```\n",
    "index combo,index combo seq,i5 name,i5 sequence,i5 well,i5 plate,i7 name,i7 sequence,i7 well,i7 plate\n",
    "0,ACCGACAAACGTTACC,iTru5_01_A,ACCGACAA,A1,iTru5_plate,iTru7_101_01,ACGTTACC,A1,iTru7_plate\n",
    "1,AGTGGCAACTGTGTTG,iTru5_01_B,AGTGGCAA,B1,iTru5_plate,iTru7_101_02,CTGTGTTG,A2,iTru7_plate\n",
    "2,CACAGACTTGAGGTGT,iTru5_01_C,CACAGACT,C1,iTru5_plate,iTru7_101_03,TGAGGTGT,A3,iTru7_plate\n",
    "3,CGACACTTGATCCATG,iTru5_01_D,CGACACTT,D1,iTru5_plate,iTru7_101_04,GATCCATG,A4,iTru7_plate\n",
    "4,GACTTGTGGCCTATCA,iTru5_01_E,GACTTGTG,E1,iTru5_plate,iTru7_101_05,GCCTATCA,A5,iTru7_plate\n",
    "5,GTGAGACTAACAACCG,iTru5_01_F,GTGAGACT,F1,iTru5_plate,iTru7_101_06,AACAACCG,A6,iTru7_plate\n",
    "6,GTTCCATGACTCGTTG,iTru5_01_G,GTTCCATG,G1,iTru5_plate,iTru7_101_07,ACTCGTTG,A7,iTru7_plate\n",
    "7,TAGCTGAGCCTATGGT,iTru5_01_H,TAGCTGAG,H1,iTru5_plate,iTru7_101_08,CCTATGGT,A8,iTru7_plate\n",
    "8,CTTCGCAATGTACACC,iTru5_02_A,CTTCGCAA,I1,iTru5_plate,iTru7_101_09,TGTACACC,A9,iTru7_plate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_combo_fp = './test_output/iTru/new_iTru_combos_Dec2017.csv'\n",
    "\n",
    "if not os.path.isfile(index_combo_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_combos = pd.read_csv(index_combo_fp)\n",
    "index_combos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assign index combo\n",
    "\n",
    "This will pick a set of index combos from the index combo for the number of samples in the `plate_df` DataFrame.\n",
    "\n",
    "Keep track of the barcode combinations used in the lab, and set `starting_combo` equal to the next unused combination.\n",
    "\n",
    "One of way of doing that might be to keep track of the number of plates run, and set `starting_combo` equal to\n",
    "384 * number of plates run + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_counter = 144\n",
    "\n",
    "starting_combo = ((plate_counter - 1) % 384) * 384\n",
    "\n",
    "indices = assign_index(len(plate_df['Sample']), index_combos, start_idx=starting_combo).reset_index()\n",
    "\n",
    "plate_df = pd.concat([plate_df, indices], axis=1)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make index pick list\n",
    "\n",
    "Format the Echo-compatible pick list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_picklist = format_index_picklist(plate_df['Sample'], plate_df[well_col], indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: write pick list to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .txt\n",
    "index_picklist_fp = './test_output/Indices/2023_08_12_Celeste_Adaptation_16-21_indices.txt'\n",
    "\n",
    "if os.path.isfile(index_picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(index_picklist_fp, 'w') as f:\n",
    "    f.write(index_picklist)\n",
    "\n",
    "!head {index_picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for calculating pooling\n",
    "\n",
    "This portion of the notebook calculates pooling based on fluorescente quantification values, and produces visual outputs to interpret and check values. \n",
    "\n",
    "As inputs, this workflow requires:\n",
    "1. A plate map DataFrame (from previous step)\n",
    "2. MiniPico output (tab-delimited text format with columns 'Concentration' and 'Well')\n",
    "\n",
    "The workflow:\n",
    "1. reads in MiniPico output and calculates estimated library concentration\n",
    "4. calculates pooling values and generates an Echo pick list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: read in MiniPico library concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter correct path to MiniPico file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_concs_fp = './test_data/Quant/MiniPico/2022_07_Celeste_Adaptation_16_17_18_21_CleanLib_quant.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_concs = read_pico_csv(lib_concs_fp, plate_reader='SpectraMax_i3x',\n",
    "                          conc_col_name='MiniPico Library DNA Concentration')\n",
    "lib_concs.rename(columns={'Well':well_col},inplace=True)\n",
    "plate_df = pd.merge(plate_df, lib_concs, on=well_col)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: calculate sample concentration from MiniPico\n",
    "\n",
    "You will want to make sure that 'size' is correct for your average library size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df['MiniPico Library Concentration'] = compute_pico_concentration(plate_df['MiniPico Library DNA Concentration'],\n",
    "                                                                        size=500)\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: visualization of MiniPico values\n",
    "\n",
    "This step will present visuals of the results, including:\n",
    "1. Scatter plot of DNA concentrations by Library concentration\n",
    "2. Plate-wise heatmap and histogram showing library concentrations\n",
    "3. per-96-well plate heatmaps and histograms showing library concentrations and sample names\n",
    "4. Plate-wise heatmap showing pooling values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration by sample DNA concentration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(14, 4))\n",
    "plate_df['Input DNA'] = plate_df['Sample DNA Concentration']*plate_df['Normalized DNA volume']/1000\n",
    "sns.regplot(x=\"Sample DNA Concentration\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax1);\n",
    "sns.boxplot(x=\"Blank\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax2);\n",
    "sns.swarmplot(x=\"Blank\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax2,\n",
    "              size=3,color='black',alpha=0.5)\n",
    "sns.scatterplot( x=\"Input DNA\",y=\"MiniPico Library DNA Concentration\",hue='Sample DNA Concentration',data=plate_df ,ax = ax3);\n",
    "ax3.legend(title='Sample DNA Concentration',loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_gdna_concs = plate_df.loc[plate_df['Blank']==True,'Sample DNA Concentration']\n",
    "samples_gdna_concs = plate_df.loc[plate_df['Blank']==False,'Sample DNA Concentration']\n",
    "mannwhitneyu(samples_gdna_concs, blanks_gdna_concs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_lib_concs = plate_df.loc[plate_df['Blank']==True,'MiniPico Library Concentration']\n",
    "samples_lib_concs = plate_df.loc[plate_df['Blank']==False,'MiniPico Library Concentration']\n",
    "mannwhitneyu(samples_lib_concs, blanks_lib_concs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, whole plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concentration and pooling values for plotting\n",
    "concs = make_2D_array(plate_df, data_col=\"MiniPico Library Concentration\", well_col=well_col).astype(float)\n",
    "dna = make_2D_array(plate_df, data_col='Sample DNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "# get information for annotation\n",
    "names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "i5 = make_2D_array(plate_df, data_col='i5 name', well_col=well_col)\n",
    "i7 = make_2D_array(plate_df, data_col='i7 name', well_col=well_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs, color_map='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plate maps for individual constituent plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(even_rows,even_cols)],\n",
    "                    annot_str= names[np.ix_(even_rows,even_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(even_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(even_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(odd_rows,even_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,even_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(odd_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: calculate pooling values for MiniPico with autopool\n",
    "\n",
    "This step will calculate the sample pooling, and update the sample data frame with the pool info.\n",
    "There are two automated methods to pool:\n",
    "1. **norm**: This will attempt to generate a normalized pool, automatically infering the best parameter for pooling.\n",
    "    - ***pool_failures***:\n",
    "        - _high_: will pool failures at the highest pooling volume from optimized pooling.\n",
    "        - _low_: will pool failures at the lowest pooling volume from optimized pooling.\n",
    "\n",
    "2. **evp**: This will pool an even volume per sample.\n",
    "    - ***total_vol***: (Optional, Default: 100µL) The total volume to pool, in uL. Each sample will be pooled at 1/N of that volume.\n",
    "\n",
    "3. **automate**: (Optional, Default = True) When False, this argument will allow one input parameters for **Legacy** arguments. \n",
    "\n",
    "> **Legacy**\n",
    "> There are legacy parameters to control pooling behaviors when autopool automation (automate=True) returns a poor result. To use these parameters, one must pass automate=False.\n",
    "\n",
    ">   - **min_conc**: (default: 0) This is the minimum concentration for a sample to be considered for pooling.\n",
    "    Set to 0 to pool all samples, regardless of concentration. Increasing this will have the \n",
    "    effect of increasing pool concentration, at the expense of samples dropping out. \n",
    ">   - **floor_conc**: This is the lowest concentration equivalent for which a sample will be \n",
    "    accurately pooled. Samples below this concentration will be pooled to the volume that they \n",
    "    would have been if they were actually that concentration. For example, if `floor_conc=20`, \n",
    "    and a sample at 20 nM pools at 500 nL, a sample at 40 nM will pool at 250 nL but a sample at \n",
    "    10 nM will still pool at 500 nL (rather than 1000). Increasing this value will have the effect \n",
    "    of increasing pool concentration, but decreasing read counts for low-concentration samples. \n",
    ">   - **total_nmol**: This is the total number of molecules to shoot for in the pool. Increasing\n",
    "    this will increase the overall volume of the pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot pooling volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = find_threshold(plate_df['MiniPico Library Concentration'], plate_df['Blank'])\n",
    "plate_df = autopool(plate_df,method='evp',total_vol=200)\n",
    "\n",
    "# visualize\n",
    "print(\"Floor concentration: {}\".format(threshold))\n",
    "vols = make_2D_array(plate_df, data_col='MiniPico Pooled Volume', well_col=well_col).astype(float)\n",
    "conc, vol = estimate_pool_conc_vol(plate_df['MiniPico Pooled Volume'], plate_df['MiniPico Library Concentration'])\n",
    "print(\"Pool concentration: {:.2f}\".format(conc))\n",
    "print(\"Pool volume: {:.2f}\".format(vol))\n",
    "with suppress(np.linalg.LinAlgError):\n",
    "    plot_plate_vals(vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vols = make_2D_array(plate_df, data_col='MiniPico Pooled Volume', well_col=well_col).astype(float)\n",
    "sns.scatterplot(x='MiniPico Library Concentration', y='MiniPico Pooled Volume',data=plate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: write pooling pick list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .csv\n",
    "picklist_fp = './test_output/Pooling/2023_09_12_Celeste_Adaptation_evp.csv'\n",
    "\n",
    "if os.path.isfile(picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklist = format_pooling_echo_pick_list(vols, max_vol_per_well=30000)\n",
    "with open(picklist_fp,'w') as f:\n",
    "    f.write(picklist)\n",
    "\n",
    "!head {picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write DataFrame to file\n",
    "\n",
    "We want to keep all that useful information together in one place so it can be easily parsed later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write the sample info DataFrame as .txt\n",
    "plate_df_fp = './test_output/QC/2023_09_12_Celeste_Adaptation_df.txt'\n",
    "\n",
    "if os.path.isfile(plate_df_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df.to_csv(plate_df_fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make sample sheet\n",
    "\n",
    "This workflow takes the pooled sample information and writes an Illumina sample sheet that can be given directly to the sequencing center. \n",
    "\n",
    "As inputs, this notebook requires:\n",
    "1. A plate map DataFrame (from previous step)\n",
    "\n",
    "The workflow:\n",
    "1. formats sample names as bcl2fastq-compatible\n",
    "2. formats sample data\n",
    "3. sets values for sample sheet fields and formats sample sheet.\n",
    "4. writes the sample sheet to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Format sample names to be bcl2fastq-compatible\n",
    "\n",
    "bcl2fastq requires *only* alphanumeric, hyphens, and underscore characters. We'll replace all non-those characters\n",
    "with underscores and add the bcl2fastq-compatible names to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df['sample sheet Sample_ID'] = plate_df['Sample'].map(bcl_scrub_name)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: format sample sheet data\n",
    "\n",
    "This step formats the data columns appropriately for the sample sheet, using the values we've calculated previously.\n",
    "\n",
    "The newly-created bcl2fastq-compatible names will be in the **`Sample ID`** and **`Sample Name`** columns. The\n",
    "original sample names will be in the **`Description`** column.\n",
    "\n",
    "Modify **`lanes`** to indicate which lanes this pool will be sequenced on.\n",
    "\n",
    "**Project Name and Project Plate values will be placed in the **`Sample_Project`** and **`Sample_Name`**\n",
    "columns, respectively.\n",
    "\n",
    "**`sequencer`** is important for making sure the i5 index is in the correct orientation for demultiplexing. `HiSeq4000`, `HiSeq3000`, `NextSeq`, `MiniSeq`, and `iSeq` all require reverse-complemented i5 index sequences. If you enter one of these exact strings in for `sequencer`, it will revcomp the i5 sequence for you.\n",
    "\n",
    "`HiSeq2500`, `MiSeq`, and `NovaSeq` will not revcomp the i5 sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer = 'iSeq'\n",
    "lanes = [1]\n",
    "\n",
    "# Knight Lab Nextera is also valid for library_construction_protocol\n",
    "metadata = {\n",
    "    'Bioinformatics': [\n",
    "        {\n",
    "         'Sample_Project': 'Celeste_Adaptation_12986',\n",
    "         'QiitaID': '12986',\n",
    "         'BarcodesAreRC': 'True',\n",
    "         'ForwardAdapter': 'GATCGGAAGAGCACACGTCTGAACTCCAGTCAC',\n",
    "         'ReverseAdapter': 'GATCGGAAGAGCGTCGTGTAGGGAAAGGAGTGT',\n",
    "         'HumanFiltering': 'True',\n",
    "         'library_construction_protocol': 'Knight Lab Kapa HyperPlus',\n",
    "         'experiment_design_description': 'isolate sequencing',\n",
    "         'contains_replicates':plate_df['contains_replicates'].all(),\n",
    "        },\n",
    "    ],\n",
    "    'Contact': [\n",
    "        {\n",
    "         'Sample_Project': 'Celeste_Adaptation_12986',\n",
    "         # non-admin contacts who want to know when the sequences\n",
    "         # are available in Qiita\n",
    "         'Email': 'rodolfo.salido@gmail.com'\n",
    "        },\n",
    "    ],\n",
    "    'Assay': 'Metagenomic',\n",
    "}\n",
    "\n",
    "sheet = make_sample_sheet(metadata, plate_df, sequencer, lanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the contents of the sample sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = validate_and_scrub_sample_sheet(sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Write the sample sheet to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the samplesheet as .csv\n",
    "sample_sheet_fp = './test_output/SampleSheets/2023_09_12_Celeste_Adaptation_12986_16_17_18_21_samplesheet.csv'\n",
    "\n",
    "if os.path.isfile(sample_sheet_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_sheet_fp,'w') as f:\n",
    "    sheet.write(f)\n",
    "    \n",
    "!head -n 30 {sample_sheet_fp}\n",
    "!echo ...\n",
    "!tail -n 15 {sample_sheet_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Distribution Summary and Pool Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: import and merge per_sample read distributions\n",
    "\n",
    "Import a tsv file with read_counts from per_sample_fastq files and merge with growing plate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reads counts from file to dataframes\n",
    "\n",
    "read_counts_df = pd.read_csv('./test_data/Demux/YYYY_MM_DD_Celeste_Adaptation_16_17_18_21_raw_counts.tsv',\n",
    "                                 sep='\\t')\n",
    "raw_read_counts_df = read_counts_df.loc[~read_counts_df['Category'].str.contains('trimmed')]\n",
    "filtered_read_counts_df = read_counts_df.loc[read_counts_df['Category'].str.contains('trimmed')]\n",
    "\n",
    "##Can also import counts from Qiita per_sample_FASTQ summaries.  \n",
    "# per_sample_fastq_counts_df = pd.read_csv('./test_data/Demux/YYYY_MM_DD_Celeste_Adaptation_16_17_18_21_per_sample_fastq.tsv',\n",
    "#                                          sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge read_counts_df with plate_df \n",
    "\n",
    "plate_df_w_reads = merge_read_counts(plate_df,raw_read_counts_df, reads_column_name='Raw Reads')\n",
    "\n",
    "plate_df_w_reads = merge_read_counts(plate_df_w_reads,filtered_read_counts_df,\n",
    "                                     reads_column_name='Filtered Reads')\n",
    "\n",
    "# plate_df_w_reads = merge_read_counts(plate_df_w_reads,per_sample_fastq_counts_fp,\n",
    "#                                      reads_column_name='Qiita Reads')\n",
    "\n",
    "plate_df_w_reads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_column = 'Filtered Reads'\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "# evenness plot\n",
    "rmax = int(round(plate_df_w_reads[reads_column].max(),-2))\n",
    "survival_df = pd.concat([read_survival(plate_df_w_reads.loc[plate_df_w_reads['Blank'] == True,\n",
    "                                                            reads_column], label='Blanks',rmax=rmax),\n",
    "                         read_survival(plate_df_w_reads.loc[plate_df_w_reads['Blank'] == False,\n",
    "                                                            reads_column], label='Samples',rmax=rmax)])\n",
    "\n",
    "ax3.set_xlabel(reads_column)\n",
    "ax3.set_ylabel('Samples')\n",
    "survival_df.plot(color = ['coral','steelblue'],ax=ax1)\n",
    "ax1.set_xlabel(reads_column)\n",
    "ax1.set_ylabel('Samples')\n",
    "\n",
    "##Histogram\n",
    "sns.histplot(plate_df_w_reads[reads_column],ax=ax3)\n",
    "\n",
    "##Regressopm\n",
    "sns.regplot(x=\"MiniPico Library DNA Concentration\", y=reads_column, data=plate_df_w_reads, ax = ax2);\n",
    "\n",
    "#Boxplot\n",
    "sns.boxplot(x=\"Blank\", y=reads_column, data=plate_df_w_reads, ax = ax4);\n",
    "sns.stripplot(x=\"Blank\", y=reads_column, data=plate_df_w_reads, ax = ax4,\n",
    "              size=3,color='black',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate iSeqnorm pooling volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df_normalized = calculate_iseqnorm_pooling_volumes(plate_df_w_reads,dynamic_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "vols = make_2D_array(plate_df_normalized, data_col='iSeq normpool volume', well_col=well_col).astype(float)\n",
    "conc, vol = estimate_pool_conc_vol(plate_df_normalized['iSeq normpool volume'], plate_df_normalized['MiniPico Library Concentration'])\n",
    "print(\"Pool concentration: {:.2f}\".format(conc))\n",
    "print(\"Pool volume: {:.2f}\".format(vol))\n",
    "with suppress(np.linalg.LinAlgError):\n",
    "    plot_plate_vals(vols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate read depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots estimate of read depth proportion, and returns a df with estimates. \n",
    "plate_df_normalized_with_estimates = estimate_read_depth(plate_df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: write pooling picklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .csv\n",
    "picklist_fp = './test_output/Pooling/YYYY_MM_DD_Celeste_Adaptation_16_17_18_21_iSeqnormpool_alt.csv'\n",
    "\n",
    "if os.path.isfile(picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklist = format_pooling_echo_pick_list(vols, max_vol_per_well=30000)\n",
    "with open(picklist_fp,'w') as f:\n",
    "    f.write(picklist)\n",
    "\n",
    "!head {picklist_fp}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "473px",
    "width": "381px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "740px",
    "left": "0px",
    "right": "1407.6666259765625px",
    "top": "112px",
    "width": "211.705px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
